import pandas as pd
from konlpy.tag import Okt
import streamlit as st
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt

st.set_page_config(page_title='Hello, Jeonnam Motel! ğŸ˜‰ ', page_icon='ğŸ˜‰')
st.sidebar.header('Hello, Jeonnam Motel!!')
st.title('ì•¼ë†€ì ì „ë‚¨ ëª¨í…” ë¦¬ë·° ì›Œë“œí´ë¼ìš°ë“œ âœâœ')

# ì—¬ëŸ¬ jsoníŒŒì¼ì˜ ê²½ë¡œ
json_files = ['./mdata/damyang_ghg_motel.json','./mdata/gwangyang_motel.json','./mdata/haenam_wjkjbg_motel.json','./mdata/mokpo_motel.json','./mdata/mooan_sinan_ya_motel.json','./mdata/najoo_hyj_motel.json','./mdata/sooncheon_motel.json','./mdata/yeosu_motel.json']

all_reviews = []   # ëª¨ë“  ë¦¬ë·°ë¥¼ ë‹´ì

for json_file in json_files:
    data = pd.read_json(json_file)
    reviews = data['í›„ê¸°'].explode().dropna().tolist()  # `explode`ë¡œ ë¦¬ìŠ¤íŠ¸í˜•íƒœë¡œ ë˜ì–´ìˆëŠ” í›„ê¸° í¼ì¹˜ê¸°
    all_reviews.extend(reviews)

fontpath = 'c:/Windows/Fonts/malgun.ttf'
twitter = Okt()

# stopwords ë¶ˆëŸ¬ì˜¤ê¸°
with open("./mdata/stopwords-kor.txt", "r", encoding="utf-8") as f:
    stopwords = f.readlines()
stopwords = [word.strip() for word in stopwords]  # ì¤„ë°”ê¿ˆ ë¬¸ì ì œê±°

one_char_words = set()  # 1ê¸€ìì§œë¦¬ ë‹¨ì–´ëŠ” stopwordsì— ì €ì¥í•˜ë„ë¡ ì§‘í•©

# í˜•ìš©ì‚¬ ì¶”ì¶œ
def extract_adjectives(text):
    tagged = twitter.pos(text, stem=True)
    words = []
    for word, tag in tagged:
        if tag == 'Adjective':
            if word not in stopwords and len(word) > 1:
                words.append(word)
            elif len(word) == 1:
                one_char_words.add(word)
    return words

    # # ëª…ì‚¬ì™€ í˜•ìš©ì‚¬ëŠ” ì¶”ì¶œí•˜ê³  ë¶ˆìš©ì–´ëŠ” ê°€ì ¸ì˜¤ì§€ë§ˆ
    # return [word for word, tag in tagged if tag in ['Noun', 'Adjective'] and word not in stopwords]

all_reviews_text = ' '.join(all_reviews)     # ì „ì²´íŒŒì¼ì—ì„œ ë¦¬ë·°ë‚´ìš© ë¬¸ìì—´ë¡œ ì—°ê²°
all_adj = extract_adjectives(all_reviews_text)    # ê°€ì ¸ì˜¨ ë¬¸ìì—´ì—ì„œ í˜•ìš©ì‚¬ ì¶”ì¶œ


counted_adj = Counter(all_adj)   # í˜•ìš©ì‚¬ì¹´ìš´íŠ¸ í•´ì„œ counter_wordsì— ì €ì¥



# 1ê¸€ì ì§œë¦¬ ë‹¨ì–´ë¥¼ stopwords-kor.txt íŒŒì¼ì— ì¶”ê°€
with open('./mdata/stopwords-kor.txt', 'a', encoding='utf-8') as f:
    for word in one_char_words:
        f.write(f'\n{word}')

# í˜•ìš©ì‚¬ìš© ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
counted_adjectives = Counter(all_adj)
with st.spinner('ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±ì¤‘... (í˜•ìš©ì‚¬)'):
    wc_adjectives = WordCloud(font_path=fontpath,
                              background_color="white",
                              width=800,
                              height=600).generate_from_frequencies(counted_adjectives)

    words = list(wc_adjectives.words_.items())
    df_words =pd.DataFrame(words,columns=['Keyword','Frequency'])
    df_words.to_csv('./mdata/jeonnam_motel_wc.csv', index=False, encoding='utf-8-sig')

    plt.figure(figsize=(10, 8))
    plt.imshow(wc_adjectives, interpolation="bilinear")
    plt.title("í˜•ìš©ì‚¬ ì›Œë“œí´ë¼ìš°ë“œ")
    plt.axis('off')

    st.pyplot(plt)  # Streamlitì— í˜•ìš©ì‚¬ìš© ì›Œë“œí´ë¼ìš°ë“œ ì¶œë ¥





# def extract_nouns(text):
#     tagged = twitter.pos(text, stem=True)
#     words = []
#     for word, tag in tagged:
#         if tag == 'Noun':
#             if word not in stopwords and len(word) > 1:
#                 words.append(word)
#             elif len(word) == 1:
#                 one_char_words.add(word)
#     return words

# ëª…ì‚¬ìš© ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
# counted_nouns = Counter(yeosu_n)
# with st.spinner('ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±ì¤‘... (ëª…ì‚¬)'):
#     wc_nouns = WordCloud(font_path=fontpath,
#                          background_color="white",
#                          width=800,
#                          height=600).generate_from_frequencies(counted_nouns)
#
#     plt.figure(figsize=(10, 8))
#     plt.imshow(wc_nouns, interpolation="bilinear")
#     plt.title("ëª…ì‚¬ ì›Œë“œí´ë¼ìš°ë“œ")
#     plt.axis('off')
#     plt.show()
#
#     st.pyplot(plt)  # Streamlitì— ëª…ì‚¬ìš© ì›Œë“œí´ë¼ìš°ë“œ ì¶œë ¥